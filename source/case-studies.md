## Case Studies & Examples

Detailed descriptions of the faculty innovations mentioned in the presentation.

### **Tony's Test Bank Experiment**
**Discipline:** Information Systems  
**Challenge:** Creating revision questions is time-consuming  
**AI Application:** Used AI to generate test bank questions  
**The Twist:** AI got some answers wrong  
**Pedagogical Innovation:** Gave questions to students WITH disclaimer - "Some answers may be wrong. Find them."  
**Outcome:** Transformed error into learning opportunity; students must understand content deeply enough to catch mistakes  
**Key Insight:** AI limitations can be pedagogical features, not just bugs

**Takeaway for Industry:** This models critical evaluation - exactly what employees need when working with AI-generated analysis or recommendations.

---

### **Ren√©e's Graphic Image Novels**
**Discipline:** Human Resource Development (Master's level)  
**Challenge:** Traditional text-based assessments don't engage students or test higher-order thinking  
**AI Application:** Students used AI image generation to create graphic novel-style assessments  
**Innovation:** First time in Australian university  
**Outcomes:**
- Increased student engagement
- Better knowledge retention
- Published research in *Education Sciences* journal
**Key Insight:** AI enabled assessment format that was previously impossible due to technical barriers; raised the bar rather than lowered it

**Published Research:** Haywood et al. (2025) - see References

**Takeaway for Industry:** AI can enable more ambitious work, not just automate existing work.

---

### **Tomayess's Feedback Mechanisms**
**Discipline:** Business Project Management, Green IT, Corporate Sustainability  
**AI Application:**
- Students use AI for brainstorming in research reports and project plans
- In-class activities comparing AI results with traditional database searches
- Currently exploring Claude Opus 4 for feedback mechanisms (Assessment 2030 grant)
**Key Insight:** Explicit comparison between AI and traditional methods helps students understand AI's strengths and limitations

**Takeaway for Industry:** Don't hide AI use - make it transparent and teach evaluation skills.

---

### **Katharina's Crisis Simulations**
**Discipline:** Business (Crisis Management focus)  
**Challenge:** Creating realistic simulation artifacts (social media posts, phone calls, news bulletins) is time-intensive  
**AI Application:** Uses AI to generate realistic crisis simulation materials  
**Outcome:** More varied, realistic scenarios without hours of manual creation  
**Key Insight:** AI excels at generating plausible content for training scenarios

**Takeaway for Industry:** Similar application in corporate training - AI can create realistic scenarios for practice without real-world risk.

---

### **Michael's Virtual Company**
**Discipline:** Information Systems  
**AI Application:**
- Created virtual company staffed by AI chatbot "employees" (finance director, HR manager, IT support)
- Students navigate workplace, extract information, make decisions
- **Assessment innovation:** Marks the conversations, not just outcomes
- Evaluates: quality of questions, ability to follow up, critical evaluation of responses
**Key Insight:** AI creates practice environment for workplace skills; assessment focuses on student's interaction process

**Takeaway for Industry:** This directly prepares students for AI-enabled workplaces where they'll interact with AI systems and colleagues.

---

### **Farveh's Research Applications**
**Discipline:** Business  
**AI Applications:**
- **Research tool:** Coding, sentiment analysis, thematic analysis, literature review
- **Teaching tool:** Creating podcasts, case studies, games, scenarios, voice clones
- Students use Gen-AI in workshop activities
**Key Insight:** AI used across both research and teaching; different tools for different contexts

**Takeaway for Industry:** Shows breadth of AI application - from analysis to content creation to student engagement.

---

### **Common Patterns Across All Examples**

1. **Domain expertise remains essential** - Faculty evaluate, refine, contextualize AI outputs
2. **AI handles scale/speed** - Repetitive tasks, data compilation, initial drafts
3. **Humans handle judgment** - Pedagogical decisions, quality control, ethical considerations
4. **Transparency** - Most faculty are open about AI use with students
5. **Iteration** - All started small, refined through experimentation

**For Advisory Board Members:**

These patterns mirror what effective AI adoption looks like in industry:
- AI for efficiency (frees humans for higher-value work)
- Human oversight for quality (domain expertise as filter)
- Transparent integration (not hidden or avoided)
- Iterative implementation (pilots before scale)
